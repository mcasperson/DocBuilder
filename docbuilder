#!/bin/bash

# This script runs as a continuous loop. It performs the following:
# 1. Download all content spec IDs from the server
# 2. Loop over the content spec IDS
# 3. Check to see if any topics have been edited since the last rebuild
# 4. If so, rebuild the content spec
# 5. Build up an index page of all the content specs
#
# Although it runs in an infinite loop, the script will only initiate as many concurrent rebuilds as the local PC has CPU cores.

LAST_REBUILD=0
# The location where info about last build times is stored
#DOCBUILDER_DATA_DIR=/home/matthew/.docbuilder
DOCBUILDER_DATA_DIR=/home/pressgang/.docbuilder
# The script to call to actually build the books
#BOOK_BUILD_SCRIPT=/home/matthew/git/DocBuilder/build_original_books.sh
BOOK_BUILD_SCRIPT=/home/pressgang/DocBuilder/build_original_books.sh
# Get the number of cores. This is used as a base line for how many processes should be running
CORE_COUNT=`grep -c ^processor /proc/cpuinfo`
# Max processes
MAX_PROCESSES=$((CORE_COUNT*2))
# The index file that is built up with each loop over the content specs
INDEX_TMP_FILE=/tmp/index.html
# The Apache root html directory
APACHE_HTML_DIR=/var/www/html
# The directory that holds the Publican ZIP files
PUBLICAN_BOOK_ZIPS=/books
# The complete directory that holds the Publican ZIP files
PUBLICAN_BOOK_ZIPS_COMPLETE=${APACHE_HTML_DIR}${PUBLICAN_BOOK_ZIPS}
# The server to connect to
#PRESSGANG_REST_SERVER=topicindex-dev.ecs.eng.bne.redhat.com:8080
PRESSGANG_REST_SERVER=topika.ecs.eng.bne.redhat.com:8080
# The format of the dates sent to the rest server. Note that the format "+%Y-%m-%dT%H:%M:%S.000%:z" was required on the dev server,
# but the original format was "+%Y-%m-%dT%H:%M:%S.000%:z". Will have to investigate this.
DATE_FORMAT=+%Y-%m-%dT%H:%M:%S.000%:z
#DATE_FORMAT=+%Y-%m-%dT%k:%M:%S.000%z

# Print the setup info
echo "Number of Cores: ${CORE_COUNT}"
echo "Max Processes: ${MAX_PROCESSES}"
echo "Data Directory: ${DOCBUILDER_DATA_DIR}"
echo "Build Script: ${BOOK_BUILD_SCRIPT}"

# Perform a check to make sure that the build script is executable
if [[ ! -x "$BOOK_BUILD_SCRIPT" ]]
then
    echo "Build script '$BOOK_BUILD_SCRIPT' is not executable or doesn't exist"
    exit 1
fi

# make sure the publican directory exists
if [[ ! -d "${PUBLICAN_BOOK_ZIPS_COMPLETE}" ]]
then
    mkdir "${PUBLICAN_BOOK_ZIPS_COMPLETE}"
fi

# Load the last rebuild time
REBUILD_FILE=${DOCBUILDER_DATA_DIR}/last_build
if [ -f ${REBUILD_FILE} ]
then
    	LAST_REBUILD=$(head -n 1 ${REBUILD_FILE})
fi

# Start the infinite loop
while "true"
do
	NOW=`date +%s`
	if [ ${LAST_REBUILD} != 0 ]
	then
				DIFF=$((${NOW}-${LAST_REBUILD}))
					REBUILD_TIME=`echo "$((${DIFF}%3600/60+1)) mins"`
	else
				REBUILD_TIME="Unknown"
	fi

	# Create the data directory if it does not exist
	if [ ! -d ${DOCBUILDER_DATA_DIR} ]
	then
		echo Data directory was not present, and was created.
		mkdir -p ${DOCBUILDER_DATA_DIR}
	fi

	# Store the last rebuild timestamp
	echo ${NOW} > ${REBUILD_FILE}
	LAST_REBUILD=${NOW}

	# Dump the HTML header boilderplate	
	echo "<html> 
    <head>
        <title>Docbuilder Index</title>
        <link rel=\"stylesheet\" href=\"index.css\"/>
        <script src=\"http://yui.yahooapis.com/3.10.0/build/yui/yui-min.js\"></script>
        <script src=\"functions-1.1.js\" ></script>
    </head>
    <body onload=\"setLangSelectLanguage()\">
        <div class=\"container\">
            <div class=\"langBar\">Language:
                <select id=\"lang\" class=\"langSelect\" onchange=\"changeLang(this)\">
                    <option selected value=\"\">English</option>
                    <option value=\"zh-Hans\">Chinese</option>
                    <option value=\"fr\">French</option>
                    <option value=\"de\">German</option>
                    <option value=\"ja\">Japanese</option>
                    <option value=\"pt-BR\">Portuguese</option>
                    <option value=\"es\">Spanish</option>
                </select>
            </div>
            <div class=\"content\">
                <div>
                    <img height=\"87\" src=\"pg.png\" width=\"879\">
                </div>
                <div style=\"margin-top:1em\">
                    <p>DocBuilder is a service that automatically rebuilds content specifications as they are created or edited.</p>
                    <p>Each content spec has three links: a link to the compiled book itself, a link to the build log, and a link to the publican log.</p>
                    <p>If a book could not be built, first check the build log. This log contains information that may indicate syntax errors in the content specification. You can also view this log to see when the document was last built.</p>
                    <p>If the build log has no errors, check the publican log. This may indicate some syntax errors in the XML.</p>
                    <p>The topics in each document include a \"Edit this topic\" link, which will take you to the topic in the CCMS.</p>
                    <p>To view the latest changes to a document, simply refresh the page.</p><p>Estimated Rebuild Time: ${REBUILD_TIME}</p>
                </div>
                <div></div>
                <div>
                    <table>
                        <tr>
                            <td>
                                ID Filter
                            </td>
                            <td>
                                <input type=\"text\" id=\"idFilter\" onkeyup=\"save_filter()\">
                            </td>
                            <td>
                                Product Filter
                            </td>
                            <td>
                                <input type=\"text\" id=\"productFilter\" onkeyup=\"save_filter()\">
                            </td>
                            <td rowspan=\"2\">
                                <button onclick=\"reset_filter()\">Reset</button>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                Version Filter
                            </td>
                            <td>
                                <input type=\"text\" id=\"versionFilter\" onkeyup=\"save_filter()\">
                            </td>
                            <td>
                                Title Filter
                            </td>
                            <td>
                                <input type=\"text\" id=\"titleFilter\" onkeyup=\"save_filter()\">
                            </td>
                        </tr>
                    </table>
                </div>
                <div></div>
            </div>
        </div>
        <script>
            // build the array that holds the details of the books
            var data = [" > ${INDEX_TMP_FILE}

	# The curl command to return the list of specs
	#CURL_SPECS_COMMAND=$(curl --silent 'http://${PRESSGANG_REST_SERVER}/pressgang-ccms/rest/1/topics/get/json/query\;tag268=1?expand=%7B%22branches%22%3A%5B%7B%22trunk%22%3A%7B%22name%22%3A%20%22topics%22%7D%7D%5D%7D' | grep -Po '(?<="id":)[0-9]+')
	CURL_SPECS_COMMAND=$(curl --silent http://${PRESSGANG_REST_SERVER}/pressgang-ccms/rest/1/contentspecs/get/json/query\;?expand=%7B%22branches%22%3A%5B%7B%22trunk%22%3A%7B%22name%22%3A%20%22contentSpecs%22%7D%7D%5D%7D | grep -Po '(?<="id":)[0-9]+')
            
	# Loop over each content spec ID
	for CS_ID in ${CURL_SPECS_COMMAND}
	do
		#CONTENT_SPEC=$(curl --silent http://${PRESSGANG_REST_SERVER}/pressgang-ccms/rest/1/topic/get/json/${CS_ID})
		CONTENT_SPEC=$(curl --silent http://${PRESSGANG_REST_SERVER}/pressgang-ccms/rest/1/contentspec/get/json+text/${CS_ID}?expand=%7B%22branches%22%3A%5B%7B%22trunk%22%3A%7B%22name%22%3A%20%22text%22%7D%7D%5D%7D)
		
		TITLE=$(echo ${CONTENT_SPEC} | grep -Po '(?<="title":").*?(?=",)')
		PRODUCT=$(echo ${CONTENT_SPEC} | sed -n "s/^.*\\\nProduct\\s*=\\s*\([0-9A-Za-z_.][0-9A-Za-z_. -]*\)\(\\\\r\)\?\\\\n.*$/\1/p")
		VERSION=$(echo ${CONTENT_SPEC} | sed -n "s/^.*\\\nVersion\\s*=\\s*\([0-9A-Za-z_. -]*\)\(\\\\r\)\?\\\\n.*$/\1/p")
		
		PRODUCT=${PRODUCT//\'/\\\'}
		TITLE=${TITLE//\'/\\\'}
	
		# Sleep until a core is free for another publican build
		PUBLICAN_COUNT=$(ps -ef | grep -v grep | grep publican | wc -l)
		CSPROCESSOR_COUNT=$(ps -ef | grep -v grep | grep csprocessor.jar | wc -l)
		echo ${PUBLICAN_COUNT} instances of publican running.
		echo ${CSPROCESSOR_COUNT} instances of csprocessor running. 
		
		while [ $((${PUBLICAN_COUNT} + ${CSPROCESSOR_COUNT})) -ge ${MAX_PROCESSES} ]
		do
			echo Sleeping until publican and csprocessor finish
			sleep 10;
			
			PUBLICAN_COUNT=$(ps -ef | grep -v grep | grep publican | wc -l)
			CSPROCESSOR_COUNT=$(ps -ef | grep -v grep | grep csprocessor.jar | wc -l)
			echo ${PUBLICAN_COUNT} instances of publican running.
			echo ${CSPROCESSOR_COUNT} instances of csprocessor running. 
		done
		
		CS_FILENAME=${DOCBUILDER_DATA_DIR}/${CS_ID}
		RECOMPILE=true
		
		# Create the data directory if it does not exist
		if [ ! -d ${DOCBUILDER_DATA_DIR} ]
		then
			echo Data directory was not present, and was created.
			mkdir -p ${DOCBUILDER_DATA_DIR}
		fi

		# A sanity check to make sure that we are not skipping content specs that failed to build for some reason
		if [ ! -f /var/www/html/${CS_ID}/index.html ]
		then
			if [ -f ${CS_FILENAME} ]
			then
				echo "Last build for ${CS_ID} failed because there is no index.html"
			else
				echo "Last compile data was not found for ${CS_ID} and was set to now."
			fi

			DATE=$(date "${DATE_FORMAT}")
			echo ${DATE} > ${CS_FILENAME}			

		else
			# Check for the last time we recompiled the content spec
			if [ -f ${CS_FILENAME} ]
			then
				echo "Last compile data was found for ${CS_ID}. Checking for changes."
		
				LAST_COMPILE=$(head -n 1 ${CS_FILENAME})
				LAST_COMPILE_ENCODED=$(perl -MURI::Escape -e 'print uri_escape($ARGV[0]);' "$LAST_COMPILE") 
				LAST_COMPILE_ENCODED=$(perl -MURI::Escape -e 'print uri_escape($ARGV[0]);' "$LAST_COMPILE_ENCODED") 			
			
				NUMBER_TOPICS=$(curl --silent  "http://${PRESSGANG_REST_SERVER}/pressgang-ccms/rest/1/topics/get/json/query;startEditDate=${LAST_COMPILE_ENCODED};topicIncludedInSpec=${CS_ID}?expand=%7B%22branches%22%3A%5B%7B%22trunk%22%3A%7B%22name%22%3A%20%22topics%22%7D%7D%5D%7D" | grep -Po '(?<="size":)[0-9]+')
					
				#SPEC_HAS_CHANGED=$(curl --silent  "http://${PRESSGANG_REST_SERVER}/pressgang-ccms/rest/1/topics/get/json/query;startEditDate=${LAST_COMPILE_ENCODED};topicIds=${CS_ID}?expand=%7B%22branches%22%3A%5B%7B%22trunk%22%3A%7B%22name%22%3A%20%22topics%22%7D%7D%5D%7D" | grep -Po '(?<="size":)[0-9]+')	
				SPEC_HAS_CHANGED=$(curl --silent  "http://${PRESSGANG_REST_SERVER}/pressgang-ccms/rest/1/contentspecs/get/json+text/query;startEditDate=${LAST_COMPILE_ENCODED};contentSpecIds=${CS_ID}?expand=%7B%22branches%22%3A%5B%7B%22trunk%22%3A%7B%22name%22%3A%20%22contentSpecs%22%7D%7D%5D%7D" | grep -Po '(?<="size":)[0-9]+')	
			
				#echo ${NUMBER_TOPICS}
				#echo ${SPEC_HAS_CHANGED}
			
				if [[ ${NUMBER_TOPICS} -eq "0" ]] && [[ ${SPEC_HAS_CHANGED} -eq "0" ]]
				then
					RECOMPILE=false
					echo "No changes were found for ${CS_ID}."
				else
					date "${DATE_FORMAT}" > ${CS_FILENAME}
				fi
			else
				echo "Last compile data was not found for ${CS_ID} and was set to now."
		
				date "${DATE_FORMAT}" > ${CS_FILENAME}
			fi
		fi		

		LAST_COMPILE=$(head -n 1 ${CS_FILENAME})

		# Build the book
		if [ ${RECOMPILE} = "true" ]
		then
			echo Recompiling ${CS_ID}
		
			${BOOK_BUILD_SCRIPT} ${CS_ID} ${CS_ID} > /dev/null 2>&1 &
		fi
		
		# find the latest publican file
		# This will actually be empty the first time around, because the ${BOOK_BUILD_SCRIPT} is run as a background
		# process, and during the first run there are no zip files that match, and the script won't have gotten to
		# the point of creating them. The second run will pick up the ZIP file though, so the only downside is that
		# for a single run, the link to the ZIP file will just list the directory.
		LATEST_PUBLICAN_BOOK=$(find "${PUBLICAN_BOOK_ZIPS_COMPLETE}" -name "${CS_ID}*.zip" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d" ")
		
		# Get just the file name
		LATEST_PUBLICAN_BOOK_FILENAME=${LATEST_PUBLICAN_BOOK##*/}
		
		# Find the number of Publican ZIP files for this spec
		PUBLICAN_ZIP_COUNT=$(find "${PUBLICAN_BOOK_ZIPS_COMPLETE}" -maxdepth 1 -type f -name "${CS_ID}*.zip" | wc -l)
		
		# Remove any Publican ZIP files more than an hour old if there are more than two
		if [[ ${PUBLICAN_ZIP_COUNT} -gt "1" ]]
		then
				find ${PUBLICAN_BOOK_ZIPS_COMPLETE} -name "${CS_ID}*.zip" -type f -mmin +360 -delete
		fi
		
		# URL Encode the link to the Publican book
		ESCAPED_PUBLICAN_BOOK_URL=$(perl -MURI::Escape -e "print uri_escape(\"${LATEST_PUBLICAN_BOOK_FILENAME}\");")
		
		# Add an entry to the index page
		#echo "{ 
		#	idRaw: ${CS_ID}, 
		#	id: '<a href=\"http://skynet.usersys.redhat.com:8080/pressgang-ccms-ui/#SearchResultsAndTopicView;query;topicIds=${CS_ID}\" target=\"_top\">${CS_ID}</a>', 
		#	versionRaw: '${VERSION}', 
		#	version: '<a href=\"http://skynet.usersys.redhat.com:8080/pressgang-ccms-ui/#DocBuilderView;${CS_ID}\" target=\"_top\">${VERSION}</a>', 
		#	productRaw: '${PRODUCT}', 
		#	product: '<a href=\"http://skynet.usersys.redhat.com:8080/pressgang-ccms-ui/#DocBuilderView;${CS_ID}\" target=\"_top\">${PRODUCT}</a>', 
		#	titleRaw: '${TITLE}', title: '<a href=\"http://skynet.usersys.redhat.com:8080/pressgang-ccms-ui/#DocBuilderView;${CS_ID}\"  target=\"_top\">${TITLE}</a>', remarks: '<a href=\"${CS_ID}/remarks\"><button>With Remarks</button></a>', 
		#	buildlog: '<a href=\"${CS_ID}/build.log\"><button>Build Log</button></a>' , 
		#	publicanbook: '<a href=\"${PUBLICAN_BOOK_ZIPS}/${ESCAPED_PUBLICAN_BOOK_URL}\"><button>Publican ZIP</button></a>', 
		#	publicanlog: '<a href=\"${CS_ID}/publican.log\"><button>Publican Log</button></a>',
		#	lastcompile: '${LAST_COMPILE}'
		#}," >> ${INDEX_TMP_FILE}
		
		echo "{ 
			idRaw: ${CS_ID}, 
			id: '<a href=\"http://skynet.usersys.redhat.com:8080/pressgang-ccms-ui/#ContentSpecFilteredResultsAndContentSpecView;query;contentSpecIds=${CS_ID}\" target=\"_top\">${CS_ID}</a>', 
			versionRaw: '${VERSION}', 
			version: '<a href=\"http://skynet.usersys.redhat.com:8080/pressgang-ccms-ui/#DocBuilderView;${CS_ID}\" target=\"_top\">${VERSION}</a>', 
			productRaw: '${PRODUCT}', 
			product: '<a href=\"http://skynet.usersys.redhat.com:8080/pressgang-ccms-ui/#DocBuilderView;${CS_ID}\" target=\"_top\">${PRODUCT}</a>', 
			titleRaw: '${TITLE}', title: '<a href=\"http://skynet.usersys.redhat.com:8080/pressgang-ccms-ui/#DocBuilderView;${CS_ID}\"  target=\"_top\">${TITLE}</a>', remarks: '<a href=\"${CS_ID}/remarks\"><button>With Remarks</button></a>', 
			buildlog: '<a href=\"${CS_ID}/build.log\"><button>Build Log</button></a>' , 
			publicanbook: '<a href=\"${PUBLICAN_BOOK_ZIPS}/${ESCAPED_PUBLICAN_BOOK_URL}\"><button>Publican ZIP</button></a>', 
			publicanlog: '<a href=\"${CS_ID}/publican.log\"><button>Publican Log</button></a>',
			lastcompile: '${LAST_COMPILE}'
		}," >> ${INDEX_TMP_FILE}
		
		# Break here to process only 1 content spec. This is useful when testing code changes.
		#break

		# Add a small sleep to give the server a break
		sleep .25
	done
	
	# Finish the index page, and copy to the www dir
	echo " ];

            rebuildTimeout = null;

            productFilter.value = localStorage[\"productFilter\"] || \"\";
            titleFilter.value = localStorage[\"titleFilter\"] || \"\";
            versionFilter.value = localStorage[\"versionFilter\"] || \"\";
            idFilter.value = localStorage[\"idFilter\"] || \"\";

            save_filter = function() {
                localStorage[\"productFilter\"] = productFilter.value;
                localStorage[\"titleFilter\"] = titleFilter.value;
                localStorage[\"versionFilter\"] = versionFilter.value;
                localStorage[\"idFilter\"] = idFilter.value;

                if (rebuildTimeout) {
                    window.clearTimeout(rebuildTimeout);
                    rebuildTimeout = null;
                }

                rebuildTimeout = setTimeout(function(){
                    build_table(data);
                    rebuildTimeout = null;
                    },1000);
            }

            reset_filter = function() {
                localStorage[\"productFilter\"] = \"\";
                localStorage[\"titleFilter\"] = \"\";
                localStorage[\"versionFilter\"] = \"\";
                localStorage[\"idFilter\"] = \"\";

                productFilter.value = \"\";
                titleFilter.value = \"\";
                versionFilter.value = \"\";
                idFilter.value = \"\";

                if (rebuildTimeout) {
                    window.clearTimeout(rebuildTimeout);
                    rebuildTimeout = null;
                }

                build_table(data);
            }

            build_table(data);
        </script>
    </body>
</html>" >> ${INDEX_TMP_FILE}
	rm -f /var/www/html/index.html.old
	mv /var/www/html/index.html /var/www/html/index.html.old
	cp  ${INDEX_TMP_FILE} /var/www/html
	
	echo "Finished rebuild of specs. Sleeping for a minute until starting again"
	
	# Give the server a break before starting again
	sleep 60
done
